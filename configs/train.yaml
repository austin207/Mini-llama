train:
  batch_size: 16
  epochs: 30                   # Reduced from 100
  lr: 1e-4                     # Reduced from 5e-4
  weight_decay: 0.1            # Increased from 0.01
  seed: 42
  checkpoint_interval_steps: 100
  inference_interval_steps: 200
  validation_split: 0.2        # Increased from 0.1
  paths:
    data: "data/corpus_ids.npy"
    tokenizer: "src/tokenizer/llama.model"
    checkpoints: "checkpoints"
